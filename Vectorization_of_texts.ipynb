{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2204df0f",
   "metadata": {},
   "source": [
    "# Vectorization of Tekenized Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34d8a131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5fbba69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    stem = nltk.stem.SnowballStemmer('english')\n",
    "    text = text.lower()\n",
    "\n",
    "    for token in nltk.word_tokenize(text):\n",
    "        if token in string.punctuation: continue\n",
    "        yield stem.stem(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2a25c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"The elephant sneezed at the sight of potatoes.\",\n",
    "    \"Bats can see via echolocation. See the bat sight sneeze!\",\n",
    "    \"Wondering, she opened the door to the studio.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd729df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"The faster kishore got to the store and store got\", \n",
    "    \"the faster kishore got out got out again\",\n",
    "    \"the faster kishore got home faster home home home\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "311fb21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def vectorize(doc):\n",
    "    features = defaultdict(int)\n",
    "    for token in tokenize(doc):\n",
    "        features[token] += 1\n",
    "    return features\n",
    "\n",
    "vectors = map(vectorize, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fbea486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[defaultdict(int,\n",
       "             {'the': 2,\n",
       "              'faster': 1,\n",
       "              'kishor': 1,\n",
       "              'got': 2,\n",
       "              'to': 1,\n",
       "              'store': 2,\n",
       "              'and': 1}),\n",
       " defaultdict(int,\n",
       "             {'the': 1,\n",
       "              'faster': 1,\n",
       "              'kishor': 1,\n",
       "              'got': 2,\n",
       "              'out': 2,\n",
       "              'again': 1}),\n",
       " defaultdict(int, {'the': 1, 'faster': 2, 'kishor': 1, 'got': 1, 'home': 4})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b680be",
   "metadata": {},
   "source": [
    "# Using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3daf5ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (3, 10)\n",
      "[[0.         0.32464326 0.19173954 0.38347908 0.         0.19173954\n",
      "  0.         0.64928652 0.38347908 0.32464326]\n",
      " [0.36657365 0.         0.2165043  0.43300861 0.         0.2165043\n",
      "  0.7331473  0.         0.2165043  0.        ]\n",
      " [0.         0.         0.27506398 0.13753199 0.93144761 0.13753199\n",
      "  0.         0.         0.13753199 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X =vectorizer.fit_transform(corpus)\n",
    "print(\"Shape: \",X.shape)\n",
    "print(X.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e043011",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectors = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "540bcd72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 2, 0, 1, 0, 2, 2, 1],\n",
       "       [1, 0, 1, 2, 0, 1, 2, 0, 1, 0],\n",
       "       [0, 0, 2, 1, 4, 1, 0, 0, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed36965",
   "metadata": {},
   "source": [
    "# Term Frequency Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9605476d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 1\n",
      "faster 4\n",
      "kishore 3\n",
      "got 5\n",
      "to 1\n",
      "the 3\n",
      "store 2\n",
      "and 1\n",
      "out 2\n",
      "again 1\n",
      "home 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'The': 0.037037037037037035,\n",
       " 'faster': 0.14814814814814814,\n",
       " 'kishore': 0.1111111111111111,\n",
       " 'got': 0.18518518518518517,\n",
       " 'to': 0.037037037037037035,\n",
       " 'the': 0.1111111111111111,\n",
       " 'store': 0.07407407407407407,\n",
       " 'and': 0.037037037037037035,\n",
       " 'out': 0.07407407407407407,\n",
       " 'again': 0.037037037037037035,\n",
       " 'home': 0.14814814814814814}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tf(corpus):\n",
    "    dic={}\n",
    "    for document in corpus:\n",
    "        for word in document.split():\n",
    "            if word in dic:\n",
    "                dic[word] = dic[word] + 1\n",
    "            else:\n",
    "                dic[word]=1\n",
    "    for word,freq in dic.items():\n",
    "        print(word,freq)\n",
    "        dic[word]=freq/sum(map(len, (document.split() for document in corpus)))\n",
    "    return dic\n",
    "tf(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd098b9",
   "metadata": {},
   "source": [
    "# TF on each document in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82b7f7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(corpus):\n",
    "    tfs = []\n",
    "    for document in corpus:\n",
    "        dic={}\n",
    "        for word in document.split():\n",
    "            if word in dic:\n",
    "                dic[word]+=1\n",
    "            else:\n",
    "                dic[word]=1\n",
    "        for word,freq in dic.items():\n",
    "            print(word,freq)\n",
    "            dic[word]=freq/len(document.split())\n",
    "        tfs.append(dic)\n",
    "    return tfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "984e7d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 1\n",
      "faster 1\n",
      "kishore 1\n",
      "got 2\n",
      "to 1\n",
      "the 1\n",
      "store 2\n",
      "and 1\n",
      "the 1\n",
      "faster 1\n",
      "kishore 1\n",
      "got 2\n",
      "out 2\n",
      "again 1\n",
      "the 1\n",
      "faster 2\n",
      "kishore 1\n",
      "got 1\n",
      "home 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'The': 0.1,\n",
       "  'faster': 0.1,\n",
       "  'kishore': 0.1,\n",
       "  'got': 0.2,\n",
       "  'to': 0.1,\n",
       "  'the': 0.1,\n",
       "  'store': 0.2,\n",
       "  'and': 0.1},\n",
       " {'the': 0.125,\n",
       "  'faster': 0.125,\n",
       "  'kishore': 0.125,\n",
       "  'got': 0.25,\n",
       "  'out': 0.25,\n",
       "  'again': 0.125},\n",
       " {'the': 0.1111111111111111,\n",
       "  'faster': 0.2222222222222222,\n",
       "  'kishore': 0.1111111111111111,\n",
       "  'got': 0.1111111111111111,\n",
       "  'home': 0.4444444444444444}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd4dae3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
